{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directory\n",
    "from cnnClassifier import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('d:\\\\codes\\\\DeepLearning_Proj\\\\proj1\\\\research')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\codes\\\\DeepLearning_Proj\\\\proj1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen = True)\n",
    "class TrainingConfig:\n",
    "    root_dir                  : Path \n",
    "    trained_model_path        : Path\n",
    "    updated_base_model_path   : Path\n",
    "    training_data             : Path \n",
    "    params_epochs             : int\n",
    "    params_batch_size         : int\n",
    "    params_is_augmentation    : bool\n",
    "    params_image_size         : list\n",
    "\n",
    "@dataclass(frozen = True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir                  : Path\n",
    "    tensorboard_root_log_dir  : Path\n",
    "    checkpoint_model_filepath : Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directory([self.config.artifacts_root])\n",
    "\n",
    "    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n",
    "        config = self.config.prepare_callbacks\n",
    "        # THIS IS TAKING THE DIRECTORY NAME checkpoint_dir AND THE DIRECTORY WILL BE CREATED\n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "\n",
    "        # THE DIRECTORYES ARE CREATED IN THE BELOW CODE\n",
    "        create_directory([\n",
    "            Path(model_ckpt_dir),\n",
    "            Path(config.tensorboard_root_log_dir)\n",
    "        ])\n",
    "\n",
    "        prepare_callback_config = PrepareCallbacksConfig(\n",
    "            root_dir                  = Path(config.root_dir),\n",
    "            tensorboard_root_log_dir  = Path(config.tensorboard_root_log_dir),\n",
    "            checkpoint_model_filepath = Path(config.checkpoint_model_filepath),\n",
    "        )\n",
    "        return prepare_callback_config\n",
    "    \n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training                      = self.config.training\n",
    "        prepare_base_model            = self.config.prepare_base_model\n",
    "        params                        = self.params\n",
    "\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir , \"Chicken-fecal-images\")\n",
    "        create_directory([Path(training.root_dir)])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir                  = Path(training.root_dir),\n",
    "            trained_model_path        = Path(training.trained_model_path),\n",
    "            updated_base_model_path   = Path(prepare_base_model.update_base_model_path),\n",
    "            training_data             = Path(training_data),\n",
    "            params_epochs             = params.EPOCHS,\n",
    "            params_batch_size         = params.BATCH_SIZE,\n",
    "            params_is_augmentation    = params.AUGMENTATION,\n",
    "            params_image_size         = params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareCallback:\n",
    "    def __init__(self, config : PrepareCallbacksConfig):\n",
    "        self.config = config\n",
    "\n",
    "    @property\n",
    "    def _create_tb_callbacks(self):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        tb_running_log_dir = os.path.join(\n",
    "            self.config.tensorboard_root_log_dir,\n",
    "            f'tb_log_at_{timestamp}'\n",
    "        )\n",
    "        return tf.keras.callbacks.TensorBoard(log_dir = tb_running_log_dir)\n",
    "    \n",
    "    @property\n",
    "    def _create_ckpt_callbacks(self):\n",
    "        return tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath       = 'artifacts\\prepare_callbacks\\checkpoint_dir\\model.h5',\n",
    "            save_best_only = True\n",
    "        )\n",
    "    \n",
    "    def get_tb_ckpt_callbacks(self):\n",
    "        return [\n",
    "            self._create_tb_callbacks,\n",
    "            self._create_ckpt_callbacks\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ModelCheckPoint -> COMMONLY USED DURING TRAINING TO SAVE THE MODELS WEIGHT AT CERTAIN INTERVALS OR WHEN THE MODEL ACHIVES BETTER PERFORMANCE.\n",
    "\n",
    "tf.keras.callbacks.ModelCheckpoint(\n",
    "    \n",
    "            filepath        = self.config.checkpoint_model_filepath,   -> PATH WHERE THE WEIGHTS OF THE MODEL WILL BE SAVED\n",
    "            save_best_only  = True                                     -> SAVES ONLY THE BEST MODEL, IF THE MONITORING METRICS DOES \n",
    "                                                                          NOT IMPROVE IT WOUNT OVERWRITE THE PREV SAVED CHECKPOINT\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config : TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        # LOADING THE UPDATED BASE MODEL\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale                = 1.0/255,\n",
    "            validation_split       = 0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size            = self.config.params_image_size[:-1],\n",
    "            batch_size             = self.config.params_batch_size,\n",
    "            interpolation          = \"bilinear\"\n",
    "        )\n",
    "\n",
    "        # DATAGENERATOR_KWARGS IS PASSED INTO THE valid_datagenerator\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        # THIS DATA GENERATOR IS MADE FOR GENRATING IMAGES FOR VALIDATION\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory = self.config.training_data,\n",
    "            subset = 'validation',\n",
    "            shuffle = False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range     = 40,\n",
    "                horizontal_flip    = True,\n",
    "                width_shift_range  = 0.2,\n",
    "                height_shift_range = 0.2,\n",
    "                shear_range        = 0.2,\n",
    "                zoom_range         = 0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            # IF THE AUGMENTATION IS NOT TRUE THEN THE TRAIN_DATAGENERATOR WILL BE A REGULAR RESIZING AND NORMALIZATION\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        # THIS DATA GENERATOR IS MADE FOR GENERATING IMAGES FOR TRAINING\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory = self.config.training_data,\n",
    "            subset = 'training',\n",
    "            shuffle = True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path : Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "    def train(self, callback_list: list):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs               = self.config.params_epochs,\n",
    "            steps_per_epoch      = self.steps_per_epoch,\n",
    "            validation_steps     = self.validation_steps,\n",
    "            validation_data      = self.valid_generator,\n",
    "            callbacks            = callback_list\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path                 = self.config.trained_model_path,\n",
    "            model                = self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def train_valid_generator(self):\n",
    "\n",
    "    THIS METHOD IS USED IN THE CONTEXT OF DATA PREPROCESSING \n",
    "\n",
    "    datagenerator_kwargs = dict(\n",
    "        \n",
    "        rescale = used to normalize or scale the pixel values of image (0 <-> 1) or (1 <-> -1),\n",
    "\n",
    "        1/255 -> (0 <-> 1)range , 2/255 -> (0 <-> 2)range ...... \n",
    "\n",
    "        validation_split = defines the fraction of data that will be used for validation. 20% validation and 80% training etc......\n",
    "\n",
    "        )\n",
    "\n",
    "        ASSOCIATED WITH THE PREPARATION OF IMAGE DATA FOR TRAINING USING DATA GENERATORS.\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1], \n",
    "\n",
    "            [:-1] this will slice off the channel parameter that is 3 in our case.\n",
    "\n",
    "            this means that the target image will be of size 224 X 224 we are maintaining the RGB \n",
    "            \n",
    "            THE IMAGE SIZE IS [224,224,3](VGG166) TAKEN FROM THE PARAMS FILE\n",
    "            \n",
    "            batch_size=self.config.params_batch_size,\n",
    "\n",
    "            specifies the number of images that the model processes in each training iteration. THIS WILL AFFERCT BOTH MEMORY AND TRAINING SPEED.\n",
    "\n",
    "            interpolation = 'bilinear' \n",
    "\n",
    "            method determines how the pixel in the image are interpolated or calculated when resizing the image. \n",
    "\n",
    "            'bilinear' -> computes new pixel value by considering the weight average of the nearest 2 X 2 pixel to the target location.\n",
    "\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "    GENERATOR -> usually refers to an instance of 'ImageDataGenerator' or similar data generator used to process and load data for training or validation task.\n",
    "\n",
    "    IMAGEDATAGENERATOR -> handle the loading and processing of large dataset, especially images, they perform real - time data augmentation, normalization, resizing\n",
    "\n",
    "    the generator created from flow_from_directory -> is designed specifically to handle a subset of the available image data\n",
    "\n",
    "######## -----------------------------------------------------------------------------\n",
    "\n",
    "    .flow_from_directory -> employed for generating a data iterator or generator that reads and processes images directly from a specific directory structure.\n",
    "\n",
    "    DIRECTORY STRUCTURE -> assumes a directory structure where the subdirectory corresponds to different classes, each subdirectory contains images belonging to a respective class.\n",
    "\n",
    "    DATA LOADER -> Loads and processes image data from the provided directory, utilizing the structure to automatically assign labels based on the subdirectory name\n",
    "\n",
    "####### ------------------------------------------------------------------------------\n",
    "\n",
    "    self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "\n",
    "        directory -> the chicken fecal images will be passed over here\n",
    "\n",
    "        subset -> 'validation' configures the generator to focus on fetching and processing images exclusively reserved for evaluating the model's performance. This ensures that the model is tested on independent, unseen data.\n",
    "\n",
    "        shuffle -> it means that the order of validation images will not be shuffled, they will be processed in the order they are found in.\n",
    "\n",
    "        **dataflow_kwargs -> the above dictionary will be unpacked here.\n",
    "    )\n",
    "\n",
    "    # in the params folder we have set the augmentation to true hence the augmentation data generator will be generated.\n",
    "\n",
    "    if self.config.params_is_augmentation:\n",
    "        train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range = Specifies the range within which the images can be randomly rotated      during training, [40 then (-40 <-> +40).degrees]\n",
    "\n",
    "            horizontal_flip = Enables or disables the flipping of image randomly during training,\n",
    "\n",
    "            width_shift_range = allow shifting the width of images randomly during training,\n",
    "\n",
    "            height_shift_range = allow shifting the height of images randomly during training,\n",
    "\n",
    "            shear_range = range (tilting/slanting) of images during training,\n",
    "\n",
    "            zoom_range = defines the range for random zooming in or out of images during training,\n",
    "\n",
    "            The datagenerator_kwargs dictionary will be unpacked here.\n",
    "\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "    def train(self, callback_list: list):\n",
    "\n",
    "        # calculates the number of steps that will make up one epoch during the training process\n",
    "        self.steps_per_epoch = total number of samples in the training dataset // size of each batch during training\n",
    "\n",
    "        number of images = 200 \n",
    "        batch size       = 10 \n",
    "        steps_per_epoch = 20, meaning the model will update its weight 50 times by iterating through 50 batches.\n",
    "        Setting the number of epochs helps in determining when to stop the training process.\n",
    "\n",
    "        self.steps_per_epoch = 200/10 = 20, it specifies the number of times the model will update its weight during one epoch by iterating through the batches. \n",
    "\n",
    "        # determines the number of steps(batches) for validation\n",
    "        self.validation_steps = signifies the total number of samples in the validation dataset // specifies the size of each batch used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-03 03:44:27,221] 31 root - INFO - YAML FILE config\\config.yaml LOADED SUCCESSFULLY\n",
      "[2023-11-03 03:44:27,226] 31 root - INFO - YAML FILE params.yaml LOADED SUCCESSFULLY\n",
      "[2023-11-03 03:44:27,227] 50 root - INFO - CREATED DIRECTORY AT : artifacts\n",
      "[2023-11-03 03:44:27,228] 50 root - INFO - CREATED DIRECTORY AT : artifacts\\prepare_callbacks\\checkpoint_dir\n",
      "[2023-11-03 03:44:27,228] 50 root - INFO - CREATED DIRECTORY AT : artifacts\\prepare_callbacks\\tensorflow_log_dir\n",
      "[2023-11-03 03:44:27,231] 50 root - INFO - CREATED DIRECTORY AT : artifacts\\training\n",
      "Found 78 images belonging to 2 classes.\n",
      "Found 312 images belonging to 2 classes.\n",
      "Epoch 1/9\n",
      "31/31 [==============================] - 65s 2s/step - loss: 13.6931 - accuracy: 0.5099 - val_loss: 1.4670 - val_accuracy: 0.7857\n",
      "Epoch 2/9\n",
      "31/31 [==============================] - 68s 2s/step - loss: 3.8201 - accuracy: 0.7682 - val_loss: 5.3082 - val_accuracy: 0.5857\n",
      "Epoch 3/9\n",
      "31/31 [==============================] - 68s 2s/step - loss: 5.1045 - accuracy: 0.7285 - val_loss: 1.8891 - val_accuracy: 0.7857\n",
      "Epoch 4/9\n",
      "31/31 [==============================] - 74s 2s/step - loss: 2.2013 - accuracy: 0.8609 - val_loss: 0.8253 - val_accuracy: 0.9143\n",
      "Epoch 5/9\n",
      "31/31 [==============================] - 90s 3s/step - loss: 1.1866 - accuracy: 0.8775 - val_loss: 0.8835 - val_accuracy: 0.9143\n",
      "Epoch 6/9\n",
      "31/31 [==============================] - 89s 3s/step - loss: 2.2045 - accuracy: 0.8510 - val_loss: 1.1568 - val_accuracy: 0.9143\n",
      "Epoch 7/9\n",
      "31/31 [==============================] - 89s 3s/step - loss: 0.7593 - accuracy: 0.9172 - val_loss: 1.5017 - val_accuracy: 0.8429\n",
      "Epoch 8/9\n",
      "31/31 [==============================] - 90s 3s/step - loss: 0.7957 - accuracy: 0.8907 - val_loss: 1.0197 - val_accuracy: 0.9143\n",
      "Epoch 9/9\n",
      "31/31 [==============================] - 90s 3s/step - loss: 1.3911 - accuracy: 0.8775 - val_loss: 1.5049 - val_accuracy: 0.8714\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config = config.get_prepare_callback_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train(\n",
    "        callback_list=callback_list\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLproj1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directory\n",
    "from cnnClassifier import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('d:\\\\codes\\\\DeepLearning_Proj\\\\proj1\\\\research')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\codes\\\\DeepLearning_Proj\\\\proj1\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen = True)\n",
    "class TrainingConfig:\n",
    "    root_dir                  : Path \n",
    "    trained_model_path        : Path\n",
    "    updated_base_model_path   : Path\n",
    "    training_data             : Path \n",
    "    params_epochs             : int\n",
    "    params_batch_size         : int\n",
    "    params_is_augmentation    : bool\n",
    "    params_image_size         : list\n",
    "\n",
    "@dataclass(frozen = True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir                  : Path\n",
    "    tensorboard_root_log_dir  : Path\n",
    "    checkpoint_model_filepath : Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directory([self.config.artifacts_root])\n",
    "\n",
    "    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n",
    "        config = self.config.prepare_callbacks\n",
    "        # THIS IS TAKING THE DIRECTORY NAME checkpoint_dir AND THE DIRECTORY WILL BE CREATED\n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "\n",
    "        # THE DIRECTORYES ARE CREATED IN THE BELOW CODE\n",
    "        create_directory([\n",
    "            Path(model_ckpt_dir),\n",
    "            Path(config.tensorboard_root_log_dir)\n",
    "        ])\n",
    "\n",
    "        prepare_callback_config = PrepareCallbacksConfig(\n",
    "            root_dir                  = Path(config.root_dir),\n",
    "            tensorboard_root_log_dir  = Path(config.tensorboard_root_log_dir),\n",
    "            checkpoint_model_filepath = Path(config.checkpoint_model_filepath)\n",
    "        )\n",
    "        return prepare_callback_config\n",
    "    \n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training                      = self.config.training\n",
    "        prepare_base_model            = self.config.prepare_base_model\n",
    "        params                        = self.params\n",
    "\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir , \"Chicken-fecal-images\")\n",
    "        create_directory([training.root_dir])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir                  = Path(training.root_dir),\n",
    "            trained_model_path        = Path(training.training_model_path),\n",
    "            updated_base_model_path   = Path(prepare_base_model.update_base_model_path),\n",
    "            training_data             = Path(training_data),\n",
    "            params_epochs             = params.EPOCHS,\n",
    "            params_batch_size         = params.BATCH_SIZE,\n",
    "            params_is_augmentation    = params.AUGMENTATION,\n",
    "            params_image_size         = params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prepareCallback:\n",
    "    def __init__(self, config : PrepareCallbacksConfig):\n",
    "        self.config = config\n",
    "\n",
    "    @property\n",
    "    def _create_tb_callbacks(self):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        tb_running_log_dir = os.path.join(\n",
    "            self.config.tensorboard_root_log_dir,\n",
    "            f'tb_log_at_{timestamp}'\n",
    "        )\n",
    "        return tf.keras.callbacks.TensorBoard(log_dir = tb_running_log_dir)\n",
    "    \n",
    "    @property\n",
    "    def _create_ckpt_callbacks(self):\n",
    "\n",
    "        return tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath       = self.config.checkpoint_model_filepath,\n",
    "            save_best_only = True\n",
    "        )\n",
    "    \n",
    "    def get_tb_ckpt_callbacks(self):\n",
    "        return [\n",
    "            self._create_tb_callbacks,\n",
    "            self._create_ckpt_callbacks\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ModelCheckPoint -> COMMONLY USED DURING TRAINING TO SAVE THE MODELS WEIGHT AT CERTAIN INTERVALS OR WHEN THE MODEL ACHIVES BETTER PERFORMANCE.\n",
    "\n",
    "tf.keras.callbacks.ModelCheckpoint(\n",
    "    \n",
    "            filepath        = self.config.checkpoint_model_filepath,   -> PATH WHERE THE WEIGHTS OF THE MODEL WILL BE SAVED\n",
    "            save_best_only  = True                                     -> SAVES ONLY THE BEST MODEL, IF THE MONITORING METRICS DOES \n",
    "                                                                          NOT IMPROVE IT WOUNT OVERWRITE THE PREV SAVED CHECKPOINT\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config : TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        # LOADING THE UPDATED BASE MODEL\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale                = 1.0/255,\n",
    "            validation_split       = 0.2\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size            = self.config.params_image_size[:-1],\n",
    "            batch_size             = self.config.params_batch_size,\n",
    "            interpolation          = \"bilinear\"\n",
    "        )\n",
    "\n",
    "        # DATAGENERATOR_KWARGS IS PASSED INTO THE valid_datagenerator\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            \n",
    "        )\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def train_valid_generator(self):\n",
    "\n",
    "    THIS METHOD IS USED IN THE CONTEXT OF DATA PREPROCESSING \n",
    "\n",
    "    datagenerator_kwargs = dict(\n",
    "        \n",
    "        rescale = used to normalize or scale the pixel values of image (0 <-> 1) or (1 <-> -1),\n",
    "\n",
    "        1/255 -> (0 <-> 1)range , 2/255 -> (0 <-> 2)range ...... \n",
    "\n",
    "        validation_split = defines the fraction of data that will be used for validation. 20% validation and 80% training etc......\n",
    "\n",
    "        )\n",
    "\n",
    "        ASSOCIATED WITH THE PREPARATION OF IMAGE DATA FOR TRAINING USING DATA GENERATORS.\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1], \n",
    "\n",
    "            [:-1] this will slice off the channel parameter that is 3 in our case.\n",
    "\n",
    "            this means that the target image will be of size 224 X 224 we are maintaining the RGB \n",
    "            \n",
    "            THE IMAGE SIZE IS [224,224,3](VGG166) TAKEN FROM THE PARAMS FILE\n",
    "            \n",
    "            batch_size=self.config.params_batch_size,\n",
    "\n",
    "            specifies the number of images that the model processes in each training iteration. THIS WILL AFFERCT BOTH MEMORY AND TRAINING SPEED.\n",
    "\n",
    "            interpolation = 'bilinear' \n",
    "\n",
    "            method determines how the pixel in the image are interpolated or calculated when resizing the image. \n",
    "\n",
    "            'bilinear' -> computes new pixel value by considering the weight average of the nearest 2 X 2 pixel to the target location.\n",
    "\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "    the generator created from flow_from_directory -> is designed specifically to handle a subset of the available image data\n",
    "\n",
    "    self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "\n",
    "        directory -> the chicken fecal images will be passed over here\n",
    "\n",
    "        subset -> 'validation' the generator will focus on retrieving and processing images intended for validating the performance\n",
    "\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLproj1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
